{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch.nn as nn\nfrom torchvision import models\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-16T08:51:46.694946Z","iopub.execute_input":"2022-12-16T08:51:46.695319Z","iopub.status.idle":"2022-12-16T08:51:46.701075Z","shell.execute_reply.started":"2022-12-16T08:51:46.695287Z","shell.execute_reply":"2022-12-16T08:51:46.699842Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nimport torch.optim as optim\nclass AlexNet(nn.Module):\n    def __init__(self, num_classes=1000, init_weights=False):   \n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(  #打包\n            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2),  # input[3, 224, 224]  output[48, 55, 55] 自动舍去小数点后\n            nn.ReLU(inplace=True), #inplace 可以载入更大模型\n            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 27, 27] kernel_num为原论文一半\n            nn.Conv2d(48, 128, kernel_size=5, padding=2),           # output[128, 27, 27]\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 13, 13]\n            nn.Conv2d(128, 192, kernel_size=3, padding=1),          # output[192, 13, 13]\n            nn.ReLU(inplace=True),\n            nn.Conv2d(192, 192, kernel_size=3, padding=1),          # output[192, 13, 13]\n            nn.ReLU(inplace=True),\n            nn.Conv2d(192, 128, kernel_size=3, padding=1),          # output[128, 13, 13]\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6]\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=0.5),\n            #全链接\n            nn.Linear(128 * 6 * 6, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.5),\n            nn.Linear(2048, 2048),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.5),\n            nn.Linear(2048, num_classes),\n        )\n        if init_weights:\n            self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, start_dim=1) #展平   或者view()\n        x = self.classifier(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2022-12-16T08:51:46.703055Z","iopub.execute_input":"2022-12-16T08:51:46.703846Z","iopub.status.idle":"2022-12-16T08:51:46.718293Z","shell.execute_reply.started":"2022-12-16T08:51:46.703811Z","shell.execute_reply":"2022-12-16T08:51:46.717190Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\n\n#建立自己的dataset train_data\nclass MyDataset(Dataset):\n    def __init__(self, image_path: list, image_class: list, transform=None):\n        self.image_path = image_path\n        self.image_class = image_class\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_path)\n\n    def __getitem__(self, item):\n        img = Image.open(self.image_path[item]).convert('RGB')\n#         if img.mode != 'RGB':\n#             raise ValueError(\"image: {} isn't RGB mode\".format(self.image_path[item]))\n        label = self.image_class[item]\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2022-12-16T08:51:46.720258Z","iopub.execute_input":"2022-12-16T08:51:46.720750Z","iopub.status.idle":"2022-12-16T08:51:46.731691Z","shell.execute_reply.started":"2022-12-16T08:51:46.720714Z","shell.execute_reply":"2022-12-16T08:51:46.730635Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom torch.autograd import Variable\n\nepoch_num=20\nbatch_size=32\nlr=0.01\npath_photo='../input/bitmoji-faces-gender-recognition/BitmojiDataset/trainimages'\npath_label='../input/bitmoji-faces-gender-recognition/train.csv'\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224))\n])\n\n# temp_name = os.listdir(path_photo)\ndf=pd.read_csv(path_label)\nimage_path=[]\nlabel_path = []\nfor dir in os.listdir(path_photo):\n#     print(dir)\n    image_path.append(path_photo+'/'+str(dir))\n    # 得到所有图片label\n    if df[df.image_id == dir].iloc[0, 1]==-1:\n        label_path.append(0)\n    else:\n        label_path.append(df[df.image_id == dir].iloc[0, 1])\n\nimage_path=np.array(image_path)\nlabel_path=np.array(label_path)\n\ntrain_path,val_path,train_label,val_label=train_test_split(image_path,label_path,test_size=0.2,random_state=1)\nprint(len(train_path),len(val_path))\ntrain_data=MyDataset(train_path,train_label,transform)\nval_data=MyDataset(val_path,val_label,transform)\ntrain_loader = DataLoader(train_data, batch_size, shuffle=False)\nval_loader = DataLoader(val_data, batch_size,shuffle=False)\nprint(train_loader)\nprint(val_loader)","metadata":{"execution":{"iopub.status.busy":"2022-12-16T08:51:46.732985Z","iopub.execute_input":"2022-12-16T08:51:46.733455Z","iopub.status.idle":"2022-12-16T08:51:49.466494Z","shell.execute_reply.started":"2022-12-16T08:51:46.733351Z","shell.execute_reply":"2022-12-16T08:51:49.465482Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"2400 600\n<torch.utils.data.dataloader.DataLoader object at 0x7eff32c42a90>\n<torch.utils.data.dataloader.DataLoader object at 0x7eff30836090>\n","output_type":"stream"}]},{"cell_type":"code","source":"net=AlexNet()\nif torch.cuda.is_available():\n    net=net.cuda()\n# 参数量\nn_p=sum(x.numel() for x in net.parameters())\nprint(n_p)","metadata":{"execution":{"iopub.status.busy":"2022-12-16T08:51:49.469137Z","iopub.execute_input":"2022-12-16T08:51:49.469525Z","iopub.status.idle":"2022-12-16T08:51:49.615052Z","shell.execute_reply.started":"2022-12-16T08:51:49.469488Z","shell.execute_reply":"2022-12-16T08:51:49.613996Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"16630440\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion=nn.CrossEntropyLoss()\noptimizer=optim.SGD(net.parameters(), lr=lr) ","metadata":{"execution":{"iopub.status.busy":"2022-12-16T08:51:49.616663Z","iopub.execute_input":"2022-12-16T08:51:49.617035Z","iopub.status.idle":"2022-12-16T08:51:49.622167Z","shell.execute_reply.started":"2022-12-16T08:51:49.616999Z","shell.execute_reply":"2022-12-16T08:51:49.621189Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# 训练\nimport time\nacc=0\nn=0\nprint('start training!')\nstart=time.time()\nfor epoch in range(epoch_num):\n    for img,label in train_loader:\n        # 将数据移到GPU上\n        if torch.cuda.is_available():\n            img, label = img.cuda(), label.cuda()\n        # 先将optimizer梯度先置为0\n        optimizer.zero_grad()\n        output=net(img)\n        # 计算loss,图的终点处\n        loss=criterion(output,label)\n#         反向传播\n        loss.backward()\n        # 更新参数\n        optimizer.step()\n        prect =output.argmax(1)\n        num_correct=(prect==label).sum()\n        acc+=num_correct.item()\n        n+=label.shape[0]\n    print('epoch: {},  loss: {:.4} Acc: {:.6f}'.format(epoch,  loss.data.item(),acc / n))\nstart=time.time()-start\nprint(start)\n\nprint(\"train over!\")\nif not os.path.exists('./model_save'):\n    os.mkdir('./model_save')\ntorch.save(net.state_dict,os.path.join('./model_save/','epoch_{}_.pth'.format(epoch+1)))\n#     if (epoch%50 == 0) & (epoch != 0):\n#         i = epoch/50\n#         torch.save(model, 'AlexNet%03d.pth'% i)","metadata":{"execution":{"iopub.status.busy":"2022-12-16T08:56:53.123348Z","iopub.execute_input":"2022-12-16T08:56:53.123712Z","iopub.status.idle":"2022-12-16T09:01:14.503225Z","shell.execute_reply.started":"2022-12-16T08:56:53.123681Z","shell.execute_reply":"2022-12-16T09:01:14.502250Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"start training!\nepoch: 0,  loss: 0.1638 Acc: 0.972083\nepoch: 1,  loss: 0.1434 Acc: 0.972708\nepoch: 2,  loss: 0.1249 Acc: 0.973194\nepoch: 3,  loss: 0.1094 Acc: 0.973646\nepoch: 4,  loss: 0.09804 Acc: 0.974417\nepoch: 5,  loss: 0.08551 Acc: 0.975625\nepoch: 6,  loss: 0.07396 Acc: 0.976607\nepoch: 7,  loss: 0.06413 Acc: 0.977448\nepoch: 8,  loss: 0.05617 Acc: 0.978194\nepoch: 9,  loss: 0.05011 Acc: 0.979125\nepoch: 10,  loss: 0.04631 Acc: 0.979924\nepoch: 11,  loss: 0.04219 Acc: 0.980625\nepoch: 12,  loss: 0.03667 Acc: 0.981314\nepoch: 13,  loss: 0.03326 Acc: 0.981935\nepoch: 14,  loss: 0.02887 Acc: 0.982583\nepoch: 15,  loss: 0.02465 Acc: 0.983177\nepoch: 16,  loss: 0.02247 Acc: 0.983750\nepoch: 17,  loss: 0.0198 Acc: 0.984306\nepoch: 18,  loss: 0.01774 Acc: 0.984825\nepoch: 19,  loss: 0.01626 Acc: 0.985313\n261.1684060096741\ntrain over!\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n# 模型评估\nnet.eval()\neval_loss=0\neval_acc=0\nfor img,label in val_loader:\n    if torch.cuda.is_available():\n        img=img.cuda()\n        label=label.cuda()\n    out=net(img)\n    loss=criterion(out,label)\n    eval_loss+=loss.item()*label.size(0)\n    prect =out.argmax(1)\n    num_correct=(prect==label).sum()\n    eval_acc+=num_correct.item()\nprint('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(val_data)), eval_acc / (len(val_data))))\n\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2022-12-16T09:01:23.554463Z","iopub.execute_input":"2022-12-16T09:01:23.554832Z","iopub.status.idle":"2022-12-16T09:01:26.700550Z","shell.execute_reply.started":"2022-12-16T09:01:23.554794Z","shell.execute_reply":"2022-12-16T09:01:26.699475Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Test Loss: 0.024324, Acc: 0.995000\n","output_type":"stream"}]},{"cell_type":"code","source":"# 测试\nimport torch\nimport pandas as pd\ntestimg_path='../input/bitmoji-faces-gender-recognition/BitmojiDataset/testimages'\nsubmission_path='../input/bitmoji-faces-gender-recognition/sample_submission.csv'\n\ncnt=0\ntest_df=pd.read_csv(submission_path)\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224))\n])\n\n# net.eval()\nwith torch.no_grad():\n    parent_list=os.listdir(testimg_path)\n    parent_list.sort()\n#     print(parent_list)\n    for img_name in parent_list:\n        img_path = os.path.join(testimg_path, img_name)\n        img = Image.open(img_path).convert('RGB')\n        img = transform(img)\n        if torch.cuda.is_available():\n            img=img.cuda()\n        img = img.unsqueeze(0)\n        prect = int(net(img).argmax(1))\n        if prect==0:\n            prect=-1\n#         print(prect)\n        test_df['is_male'].iloc[cnt:cnt+1]=str(prect)\n        cnt+=1\n# test_df.iloc[:,1:2]\nprint(test_df)    \ntest_df.to_csv('./sample_submission.csv',index=False,header=True)\nprint('test_over!')\n       ","metadata":{"execution":{"iopub.status.busy":"2022-12-16T08:56:16.277254Z","iopub.execute_input":"2022-12-16T08:56:16.277622Z","iopub.status.idle":"2022-12-16T08:56:24.280711Z","shell.execute_reply.started":"2022-12-16T08:56:16.277585Z","shell.execute_reply":"2022-12-16T08:56:24.279088Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_block(indexer, value, name)\n","output_type":"stream"},{"name":"stdout","text":"      image_id is_male\n0     3000.jpg      -1\n1     3001.jpg      -1\n2     3002.jpg      -1\n3     3003.jpg       1\n4     3004.jpg      -1\n...        ...     ...\n1079  4079.jpg      -1\n1080  4080.jpg       1\n1081  4081.jpg       1\n1082  4082.jpg      -1\n1083  4083.jpg       1\n\n[1084 rows x 2 columns]\ntest_over!\n","output_type":"stream"}]}]}